{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d83b7a",
   "metadata": {},
   "source": [
    "# Installations and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "81b2600f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in d:\\anaconda3\\lib\\site-packages (1.26.0)\n"
     ]
    }
   ],
   "source": [
    "# Installations of libraries\n",
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "0f6f2e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in d:\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in d:\\anaconda3\\lib\\site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "1ccadbc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfminer in d:\\anaconda3\\lib\\site-packages (20191125)\n",
      "Requirement already satisfied: pycryptodome in d:\\anaconda3\\lib\\site-packages (from pdfminer) (3.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pdfminer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "b3782cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in d:\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in d:\\anaconda3\\lib\\site-packages (from textblob) (3.6.5)\n",
      "Requirement already satisfied: click in d:\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.3)\n",
      "Requirement already satisfied: joblib in d:\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in d:\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.62.3)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "91b175d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in d:\\anaconda3\\lib\\site-packages (3.2.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in d:\\anaconda3\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in d:\\anaconda3\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (21.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in d:\\anaconda3\\lib\\site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in d:\\anaconda3\\lib\\site-packages (from spacy) (8.0.15)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in d:\\anaconda3\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (0.7.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in d:\\anaconda3\\lib\\site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in d:\\anaconda3\\lib\\site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.10.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda3\\lib\\site-packages (from jinja2->spacy) (1.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "c8c8799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in d:\\anaconda3\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.6)\n",
      "Requirement already satisfied: pathy>=0.3.5 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.15)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.0)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in d:\\anaconda3\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in d:\\anaconda3\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in d:\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in d:\\anaconda3\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in d:\\anaconda3\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.2.0\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-15 22:47:36.565750: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-03-15 22:47:36.565813: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "115770cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Jeremy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Jeremy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package tagsets to\n",
      "[nltk_data]     C:\\Users\\Jeremy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package tagsets is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Jeremy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\Jeremy\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk download\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('tagsets')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "id": "21c51794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from PyPDF2 import PdfFileReader, PdfFileWriter\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from textblob import TextBlob\n",
    "from nltk.chunk import conlltags2tree, tree2conlltags\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from spacy import displacy\n",
    "\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import io\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc143c2b",
   "metadata": {},
   "source": [
    "# PDF Article to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "id": "5db866f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate pdf file\n",
    "pdf_file = \"../res/who_int_0.pdf\"\n",
    "# Initiate dump file\n",
    "pdf_to_text = \"../dump/pdf_to_text.txt\"\n",
    "df_to_text = \"../dump/df_to_text.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "0ac78e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/64467930/python-pypdf2-extracttext-not-working\n",
    "inFile = open(pdf_file, 'rb')\n",
    "resMgr = PDFResourceManager()\n",
    "retData = io.StringIO()\n",
    "TxtConverter = TextConverter(resMgr, retData,laparams = LAParams())\n",
    "interpreter = PDFPageInterpreter(resMgr, TxtConverter)\n",
    "\n",
    "# Process each pages\n",
    "for page in PDFPage.get_pages(inFile): \n",
    "    interpreter.process_page(page)\n",
    "    \n",
    "\n",
    "# Write to text temporary file\n",
    "txt = retData.getvalue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "968ab7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3/15/22, 10:32 AM  Is the pandemic ending soon?',\n",
       " 'Western Pacific Philippines  ©  Opinion: Is the pandemic ending soon?']"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Acquire sentences\n",
    "blob = TextBlob(txt)\n",
    "sentences = []\n",
    "\n",
    "# Append to sentences whilest removing 'sentence(...)' on each sentences/list elements\n",
    "for s in blob.sentences:\n",
    "     sentences.append(str(s).strip()),\n",
    "\n",
    "cleaned_sentences = []\n",
    "\n",
    "# Append to cleaned_sentences whilest removing new lines or '\\n'\n",
    "for x in sentences:\n",
    "     cleaned_sentences.append(x.replace(\"\\n\", \" \"))\n",
    "\n",
    "# Sample data inside cleaned_sentences\n",
    "cleaned_sentences[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "id": "066ec123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Open new temp text file and write cleaned sentences on a per line basis\n",
    "with open(pdf_to_text, 'w') as f: \n",
    "     f.write('\\n'.join(cleaned_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b813bd6",
   "metadata": {},
   "source": [
    "# Text to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "id": "e987a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open text file\n",
    "raw = open(pdf_to_text).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "34c0db0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_nlp = nlp(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "d5dcd6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [x for x in raw_nlp.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "id": "cfbfc55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "sentence_index = []\n",
    "\n",
    "# Contain tokenized data and its corresponding sentence index\n",
    "for idx1 in range(len(sentences)):\n",
    "    temporary_sentence = sentences[idx1]\n",
    "    temporary_tokens = [x for x in temporary_sentence]\n",
    "    \n",
    "    for idx2, val in enumerate(temporary_tokens):\n",
    "        sentence_index.append(idx1)\n",
    "\n",
    "print(sentence_index[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "id": "efaa9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_type = ([(x, x.pos_, spacy.explain(x.tag_), x.tag_, x.ent_iob_, x.ent_type_) for x in raw_nlp])\n",
    "\n",
    "# Words and Tags list\n",
    "word, pos, e_tags, tags, iob, e_type = zip(*ent_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "id": "7222895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464 <class 'list'>\n",
      "1464 <class 'tuple'>\n",
      "1464 <class 'tuple'>\n",
      "1464 <class 'tuple'>\n",
      "1464 <class 'tuple'>\n",
      "1464 <class 'tuple'>\n",
      "1464 <class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "# Length must be the same\n",
    "print(len(sentence_index), type(sentence_index))\n",
    "print(len(word), type(word))\n",
    "print(len(pos), type(pos))\n",
    "print(len(e_tags), type(e_tags))\n",
    "print(len(tags), type(tags))\n",
    "print(len(iob), type(iob))\n",
    "print(len(e_type), type(e_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "a3e9fd64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3/15/22, 'NUM', 'cardinal number', 'CD', 'B', 'CARDINAL'),\n",
       " (,, 'PUNCT', 'punctuation mark, comma', ',', 'O', '')]"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_type[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "e2ab53f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence_Index</th>\n",
       "      <th>Token</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Explained_Tag</th>\n",
       "      <th>Tag</th>\n",
       "      <th>iob_Tag</th>\n",
       "      <th>Entity_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3/15/22</td>\n",
       "      <td>NUM</td>\n",
       "      <td>cardinal number</td>\n",
       "      <td>CD</td>\n",
       "      <td>B</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation mark, comma</td>\n",
       "      <td>,</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10:32</td>\n",
       "      <td>NUM</td>\n",
       "      <td>cardinal number</td>\n",
       "      <td>CD</td>\n",
       "      <td>B</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>AM</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>noun, singular or mass</td>\n",
       "      <td>NN</td>\n",
       "      <td>I</td>\n",
       "      <td>TIME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>whitespace</td>\n",
       "      <td>_SP</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>81</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>punctuation mark, sentence closer</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>82</td>\n",
       "      <td>\\n</td>\n",
       "      <td>SPACE</td>\n",
       "      <td>whitespace</td>\n",
       "      <td>_SP</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>82</td>\n",
       "      <td>https://www.who.int/philippines/news/detail/11...</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>noun, proper singular</td>\n",
       "      <td>NNP</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1462</th>\n",
       "      <td>82</td>\n",
       "      <td></td>\n",
       "      <td>SPACE</td>\n",
       "      <td>whitespace</td>\n",
       "      <td>_SP</td>\n",
       "      <td>O</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1463</th>\n",
       "      <td>82</td>\n",
       "      <td>3/3</td>\n",
       "      <td>NUM</td>\n",
       "      <td>cardinal number</td>\n",
       "      <td>CD</td>\n",
       "      <td>B</td>\n",
       "      <td>CARDINAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1464 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence_Index                                              Token  \\\n",
       "0                  0                                            3/15/22   \n",
       "1                  0                                                  ,   \n",
       "2                  0                                              10:32   \n",
       "3                  0                                                 AM   \n",
       "4                  0                                                      \n",
       "...              ...                                                ...   \n",
       "1459              81                                                  .   \n",
       "1460              82                                                 \\n   \n",
       "1461              82  https://www.who.int/philippines/news/detail/11...   \n",
       "1462              82                                                      \n",
       "1463              82                                                3/3   \n",
       "\n",
       "        Pos                      Explained_Tag  Tag iob_Tag Entity_Type  \n",
       "0       NUM                    cardinal number   CD       B    CARDINAL  \n",
       "1     PUNCT            punctuation mark, comma    ,       O              \n",
       "2       NUM                    cardinal number   CD       B        TIME  \n",
       "3      NOUN             noun, singular or mass   NN       I        TIME  \n",
       "4     SPACE                         whitespace  _SP       O              \n",
       "...     ...                                ...  ...     ...         ...  \n",
       "1459  PUNCT  punctuation mark, sentence closer    .       O              \n",
       "1460  SPACE                         whitespace  _SP       O              \n",
       "1461  PROPN              noun, proper singular  NNP       O              \n",
       "1462  SPACE                         whitespace  _SP       O              \n",
       "1463    NUM                    cardinal number   CD       B    CARDINAL  \n",
       "\n",
       "[1464 rows x 7 columns]"
      ]
     },
     "execution_count": 771,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(zip(sentence_index, word, pos, e_tags, tags, iob, e_type), \n",
    "                  columns=[\"Sentence_Index\", \"Token\", \"Pos\", \"Explained_Tag\", \"Tag\", \"iob_Tag\", \"Entity_Type\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "8a179a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to csv\n",
    "df.to_csv('../data/csv_dataset/data.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffe3a6",
   "metadata": {},
   "source": [
    "# DataFrame to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "c912f99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/15/22, 10:32 AM  Is the pandemic ending soon?\n"
     ]
    }
   ],
   "source": [
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "text = nlp(raw)\n",
    "\n",
    "sentences = [x.text for x in text.sents]\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "deab0f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'CARDINAL': 9,\n",
       "         'TIME': 3,\n",
       "         'ORG': 16,\n",
       "         'DATE': 6,\n",
       "         'PERSON': 4,\n",
       "         'GPE': 10,\n",
       "         'PERCENT': 1,\n",
       "         'PRODUCT': 2,\n",
       "         'LOC': 2,\n",
       "         'NORP': 1,\n",
       "         'WORK_OF_ART': 1})"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = [x.label_ for x in text.ents]\n",
    "Counter(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "cd2b9884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3/15/22\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    10:32 AM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
       "</mark>\n",
       "  Is the pandemic ending soon?</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(nlp(str(sentences[0])), jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "12f16465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55\n"
     ]
    }
   ],
   "source": [
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54ece0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
